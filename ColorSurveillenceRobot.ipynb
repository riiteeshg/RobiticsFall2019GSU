{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-566e42448557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfreshest_frame\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_video_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import picamera\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import IPython\n",
    "import io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import threading\n",
    "import queue\n",
    "import IPython\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import easygopigo3 as easy \n",
    "\n",
    "mgpg = easy.EasyGoPiGo3()\n",
    "\n",
    "\n",
    "# Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    '''\n",
    "    Function to display an image within a Jupyter notebook.\n",
    "    '''\n",
    "    f = io.BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue(), width = 480, height = 360))\n",
    "    \n",
    "def detectFacesAndEyes(img_array):\n",
    "    '''\n",
    "    Function to detect eyes and faces using a Haar-Cascade classifier.\n",
    "    '''\n",
    "    gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(img_array,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img_array[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "          \n",
    "def resizeNPArray(array, width, height):\n",
    "    '''\n",
    "    Function to resize a given numpy array to another width/height,\n",
    "    whilst preserving the relative information - used for images.\n",
    "    '''\n",
    "    img = Image.fromarray(array)\n",
    "    img = img.resize((width, height), Image.ANTIALIAS)\n",
    "    resized = np.asarray(img)\n",
    "    return resized  \n",
    "    \n",
    "class ImageProcessor(threading.Thread):\n",
    "    '''\n",
    "    Thread-safe class to process a stream of jpeg sequences from a given queue.\n",
    "    '''\n",
    "    def __init__(self, thread_stopper, frames, lock):\n",
    "        '''\n",
    "        thread_stopper -> Is the event which stops the thread when set.\n",
    "        frames -> The queue from which jpeg images come (in numpy.array format).\n",
    "        lock -> Mutex for the queue.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.thread_stopper = thread_stopper\n",
    "        self.frames = frames\n",
    "        self.lock = lock\n",
    "        self.incoming = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "        self.processed = np.zeros((240, 320, 3), dtype = np.uint8)\n",
    "        \n",
    "        self.verticals = np.array(80 * [np.arange(0, 60)]).T\n",
    "        self.verticals = self.verticals[:,:,np.newaxis]\n",
    "        \n",
    "        self.horizontals = np.array(60 * [np.arange(0, 80)])\n",
    "        self.horizontals = self.horizontals[:,:,np.newaxis]\n",
    "        \n",
    "    def run(self):\n",
    "        '''\n",
    "        Main thread which runs indefinitely until <<thread_stopper>> event is set.\n",
    "        This function processes each incoming image from the queue iteratively and then displays it in this notebook.\n",
    "        '''\n",
    "        while not thread_stopper.is_set():\n",
    "            try:\n",
    "                self.lock.acquire()\n",
    "                self.incoming = self.frames.get_nowait()\n",
    "                self.position, self.processed = self.dowork(self.incoming)\n",
    "                self.frames.task_done()\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            finally:\n",
    "                self.lock.release()\n",
    "            showarray(self.processed)\n",
    "            IPython.display.clear_output(wait = True)\n",
    "            \n",
    "    def dowork(self, array):\n",
    "        '''\n",
    "        \n",
    "        array -> Is a numpy array that holds the a RGB image.\n",
    "        Function to process an image and detect spots of a given targeted color.\n",
    "        '''\n",
    "        \n",
    "        # down-sizing the image and running KMeans on it\n",
    "         \n",
    "        output = array.copy()\n",
    "        array = resizeNPArray(array, 80, 60)\n",
    "        image_and_positions = np.concatenate((array, self.verticals, self.horizontals), axis = 2)\n",
    "        reshaped = image_and_positions.reshape((60 * 80, 5))\n",
    "        kmeans = KMeans(n_clusters = 6,\n",
    "                       n_init = 1,\n",
    "                       max_iter = 300,\n",
    "                       precompute_distances = True).fit(reshaped)\n",
    "        rgb_centers = kmeans.cluster_centers_[:, 0:3]\n",
    "        \n",
    "        labels_rgb = np.empty((4800, 3))\n",
    "        for i in range(6):\n",
    "            labels_rgb[kmeans.labels_ == i] = rgb_centers[i]\n",
    "        labels_rgb = labels_rgb.reshape((60, 80, 3)).astype(np.uint8)\n",
    "        \n",
    "        # getting the closest KMeans center to the targeted color\n",
    "        diff = rgb_centers - target_color\n",
    "        closest = np.sqrt(np.power(diff, 2).sum(axis = 1))\n",
    "        closest_label = closest.argmin()\n",
    "       # print(\"closest\" + closest)\n",
    "        \n",
    "        # determining the distribution of the targeted pixels\n",
    "        # (the target pixels are identified with the label of the selected KMeans center)\n",
    "        labels = kmeans.labels_.reshape((60, 80))\n",
    "        labels = labels == closest_label\n",
    "        sum_labels_vertical = labels.sum(axis = 1)\n",
    "        sum_labels_horizontal = labels.sum(axis = 0)\n",
    "        \n",
    "        # find the countour of the spot of color\n",
    "        non_zero_elements = np.nonzero(sum_labels_vertical)\n",
    "        # multiply by 4 to get to the original size\n",
    "        min_vertical = np.min(non_zero_elements) * 4\n",
    "        max_vertical = np.max(non_zero_elements) * 4\n",
    "        non_zero_elements = np.nonzero(sum_labels_horizontal)\n",
    "        min_horizontal = np.min(non_zero_elements) * 4\n",
    "        max_horizontal = np.max(non_zero_elements) * 4\n",
    "        \n",
    "        # 4800 = 60 * 80 pixels\n",
    "        \n",
    "        if not sum_labels_vertical.sum() > color_threshold * 4800:\n",
    "            return (None, output)\n",
    "        \n",
    "        if min_vertical > 0:\n",
    "            mgpg.drive_cm(15)\n",
    "            img = Image.fromarray(output)\n",
    "            img.save(\"../photo{}.jpg\")\n",
    "            print(str(\"min: %d, max: %d\" % (min_vertical, max_vertical)))\n",
    "            output[min_vertical:max_vertical+1,min_horizontal,:] = border_color\n",
    "            output[min_vertical:max_vertical+1,max_horizontal,:] = border_color\n",
    "            output[min_vertical,min_horizontal:max_horizontal+1,:] = border_color\n",
    "            output[max_vertical,min_horizontal:max_horizontal+1,:] = border_color\n",
    "        \n",
    "        # and then draw a rectangle around the detected spot of color\n",
    "        \n",
    "        center_position = (min_vertical + max_vertical) / 2\n",
    "        return (center_position, output) \n",
    "        \n",
    "        \n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')\n",
    "frames = queue.Queue(maxsize = 10)\n",
    "thread_stopper = threading.Event()\n",
    "lock = threading.Lock() \n",
    "response = input('Choose what color you want to detect (red, green, blue): ')\n",
    "color_to_detect = 0 #[255,0,0],[0,255,0], [0,0,255] # [255,0,0] red, [0,255,0] green, [0,0,255] blue\n",
    "response = response.lower()\n",
    "\n",
    "if response == \"red\":\n",
    "    color_to_detect = [255,0,0]\n",
    "elif response == \"blue\":\n",
    "    color_to_detect = [0,0,255]\n",
    "else:\n",
    "    color_to_detect = [255,255,0]\n",
    "\n",
    "target_color = np.array(color_to_detect)\n",
    "#target_color = np.array([0, 255, 0])# white\n",
    "border_color = np.array([0,255, 0]) # green\n",
    "color_threshold = 0.05 # in percentage\n",
    "time_to_run = 60 # in seconds\n",
    "\n",
    "start = time.time()\n",
    "imageThread = ImageProcessor(thread_stopper, frames, lock)\n",
    "imageThread.start()  #add conditions to track distance from target object\n",
    "\n",
    "output = np.empty((480, 640, 3), dtype = np.uint8)\n",
    "\n",
    "with picamera.PiCamera() as camera:\n",
    "    camera.resolution = (320, 240)\n",
    "    camera.framerate = 30\n",
    "    while time.time() - start < time_to_run:\n",
    "        freshest_frame = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "        camera.capture(output, format = 'rgb', use_video_port = True) \n",
    "        camera.capture(freshest_frame, use_video_port = True, format = 'rgb')\n",
    "        #detectFacesAndEyes(freshest_frame)\n",
    "        showarray(freshest_frame)\n",
    "        IPython.display.clear_output(wait = True)\n",
    "        camera.capture_sequence([freshest_frame], use_video_port = True, format = 'rgb')\n",
    "        lock.acquire()\n",
    "        if frames.full():\n",
    "            frames.get()\n",
    "            frames.task_done()\n",
    "        else:\n",
    "            frames.put(freshest_frame)\n",
    "        #time.sleep(1)\n",
    "        lock.release()\n",
    "print(\"picamera session ended\")\n",
    "\n",
    "thread_stopper.set()\n",
    "print(\"triggered image processing thread\")\n",
    "\n",
    "imageThread.join()\n",
    "print(\"thread joined\")        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
